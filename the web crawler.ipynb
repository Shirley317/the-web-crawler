{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9627a5f0",
   "metadata": {},
   "source": [
    "1. 完整理解基础代码的功能和结果（即对每一行基础代码添加注释）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6e09c45",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'Albert Einstein', ['change', 'deep-thoughts', 'thinking', 'world']]]\n",
      "[['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'Albert Einstein', ['change', 'deep-thoughts', 'thinking', 'world']], ['“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'J.K. Rowling', ['abilities', 'choices']]]\n",
      "[['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'Albert Einstein', ['change', 'deep-thoughts', 'thinking', 'world']], ['“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'J.K. Rowling', ['abilities', 'choices']], ['“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', 'Albert Einstein', ['inspirational', 'life', 'live', 'miracle', 'miracles']]]\n",
      "[['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'Albert Einstein', ['change', 'deep-thoughts', 'thinking', 'world']], ['“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'J.K. Rowling', ['abilities', 'choices']], ['“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', 'Albert Einstein', ['inspirational', 'life', 'live', 'miracle', 'miracles']], ['“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”', 'Jane Austen', ['aliteracy', 'books', 'classic', 'humor']]]\n",
      "[['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'Albert Einstein', ['change', 'deep-thoughts', 'thinking', 'world']], ['“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'J.K. Rowling', ['abilities', 'choices']], ['“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', 'Albert Einstein', ['inspirational', 'life', 'live', 'miracle', 'miracles']], ['“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”', 'Jane Austen', ['aliteracy', 'books', 'classic', 'humor']], [\"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\", 'Marilyn Monroe', ['be-yourself', 'inspirational']]]\n",
      "[['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'Albert Einstein', ['change', 'deep-thoughts', 'thinking', 'world']], ['“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'J.K. Rowling', ['abilities', 'choices']], ['“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', 'Albert Einstein', ['inspirational', 'life', 'live', 'miracle', 'miracles']], ['“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”', 'Jane Austen', ['aliteracy', 'books', 'classic', 'humor']], [\"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\", 'Marilyn Monroe', ['be-yourself', 'inspirational']], ['“Try not to become a man of success. Rather become a man of value.”', 'Albert Einstein', ['adulthood', 'success', 'value']]]\n",
      "[['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'Albert Einstein', ['change', 'deep-thoughts', 'thinking', 'world']], ['“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'J.K. Rowling', ['abilities', 'choices']], ['“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', 'Albert Einstein', ['inspirational', 'life', 'live', 'miracle', 'miracles']], ['“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”', 'Jane Austen', ['aliteracy', 'books', 'classic', 'humor']], [\"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\", 'Marilyn Monroe', ['be-yourself', 'inspirational']], ['“Try not to become a man of success. Rather become a man of value.”', 'Albert Einstein', ['adulthood', 'success', 'value']], ['“It is better to be hated for what you are than to be loved for what you are not.”', 'André Gide', ['life', 'love']]]\n",
      "[['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'Albert Einstein', ['change', 'deep-thoughts', 'thinking', 'world']], ['“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'J.K. Rowling', ['abilities', 'choices']], ['“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', 'Albert Einstein', ['inspirational', 'life', 'live', 'miracle', 'miracles']], ['“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”', 'Jane Austen', ['aliteracy', 'books', 'classic', 'humor']], [\"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\", 'Marilyn Monroe', ['be-yourself', 'inspirational']], ['“Try not to become a man of success. Rather become a man of value.”', 'Albert Einstein', ['adulthood', 'success', 'value']], ['“It is better to be hated for what you are than to be loved for what you are not.”', 'André Gide', ['life', 'love']], [\"“I have not failed. I've just found 10,000 ways that won't work.”\", 'Thomas A. Edison', ['edison', 'failure', 'inspirational', 'paraphrased']]]\n",
      "[['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'Albert Einstein', ['change', 'deep-thoughts', 'thinking', 'world']], ['“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'J.K. Rowling', ['abilities', 'choices']], ['“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', 'Albert Einstein', ['inspirational', 'life', 'live', 'miracle', 'miracles']], ['“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”', 'Jane Austen', ['aliteracy', 'books', 'classic', 'humor']], [\"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\", 'Marilyn Monroe', ['be-yourself', 'inspirational']], ['“Try not to become a man of success. Rather become a man of value.”', 'Albert Einstein', ['adulthood', 'success', 'value']], ['“It is better to be hated for what you are than to be loved for what you are not.”', 'André Gide', ['life', 'love']], [\"“I have not failed. I've just found 10,000 ways that won't work.”\", 'Thomas A. Edison', ['edison', 'failure', 'inspirational', 'paraphrased']], [\"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\", 'Eleanor Roosevelt', ['misattributed-eleanor-roosevelt']]]\n",
      "[['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'Albert Einstein', ['change', 'deep-thoughts', 'thinking', 'world']], ['“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'J.K. Rowling', ['abilities', 'choices']], ['“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', 'Albert Einstein', ['inspirational', 'life', 'live', 'miracle', 'miracles']], ['“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”', 'Jane Austen', ['aliteracy', 'books', 'classic', 'humor']], [\"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\", 'Marilyn Monroe', ['be-yourself', 'inspirational']], ['“Try not to become a man of success. Rather become a man of value.”', 'Albert Einstein', ['adulthood', 'success', 'value']], ['“It is better to be hated for what you are than to be loved for what you are not.”', 'André Gide', ['life', 'love']], [\"“I have not failed. I've just found 10,000 ways that won't work.”\", 'Thomas A. Edison', ['edison', 'failure', 'inspirational', 'paraphrased']], [\"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\", 'Eleanor Roosevelt', ['misattributed-eleanor-roosevelt']], ['“A day without sunshine is like, you know, night.”', 'Steve Martin', ['humor', 'obvious', 'simile']]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from urllib.request import urlopen  # 导入urlopen用于打开URL\n",
    "from bs4 import BeautifulSoup       # 导入BeautifulSoup用于解析HTML\n",
    "import ssl                          # 导入ssl用于处理SSL证书\n",
    "\n",
    "context = ssl._create_unverified_context()  # 创建未验证的SSL上下文以忽略SSL证书验证\n",
    "\n",
    "all_quotes = []  # 初始化一个空列表用于存储爬取到的名言\n",
    "\n",
    "url = 'https://quotes.toscrape.com/page/1/'  # 设置目标网址\n",
    "\n",
    "# 使用urlopen请求并打开网页内容\n",
    "page = urlopen(url, context=context)  # 请求网页信息并忽略SSL证书验证\n",
    "\n",
    "# 使用HTML解析器将网页内容组合为BeautifulSoup对象\n",
    "soup = BeautifulSoup(page, 'html.parser')  # 将网页信息解析为BeautifulSoup对象\n",
    "\n",
    "# 查找所有带有quote类的<div>标签，这些标签包含每个名言的信息\n",
    "quotes = soup.find_all('div', class_='quote')\n",
    "\n",
    "# 遍历找到的每个名言\n",
    "for quote in quotes:\n",
    "    # 提取名言的文本，查找带有text类的<span>标签并提取其文本\n",
    "    text = quote.find('span', class_='text').text  \n",
    "    # 提取作者的名字，查找带有author类的<small>标签并提取其文本\n",
    "    author = quote.find('small', class_='author').text \n",
    "    # 查找带有tags类的<div>标签内的所有<a>标签\n",
    "    tags = quote.find('div', class_='tags').find_all('a')  \n",
    "\n",
    "    # 初始化一个空列表用于存储当前名言的标签\n",
    "    tags_list = []\n",
    "    # 遍历每个标签并提取其文本，每个标签的文本添加到tags_list中形成一个列表\n",
    "    for tag in tags:\n",
    "        tags_list.append(tag.text) \n",
    "    # 将名言文本、作者和标签组合为一个列表\n",
    "    single_quote = [text, author, tags_list]\n",
    "    # 将single_quote列表添加到all_quotes列表中\n",
    "    all_quotes.append(single_quote)\n",
    "    # 打印all_quotes列表以查看收集到的数据\n",
    "    print(all_quotes)\n",
    "\n",
    "# 简化版本\n",
    "# for quote in quotes:\n",
    "#     text = quote.find('span', class_='text').text\n",
    "#     author = quote.find('small', class_='author').text\n",
    "#     tags = [tag.text for tag in quote.find('div', class_='tags').find_all('a')] #直接生成列表\n",
    "#     all_quotes.append([text, author, tags])\n",
    "\n",
    "# print(all_quotes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9683bd81",
   "metadata": {},
   "source": [
    "2. 添加代码，爬取相同网站的10个页面内容，并将爬取内容存储在同一个CSV格式文件（添加性能分析，time和%prun）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6af21fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken to scrape data: 11.87 seconds\n",
      " "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "import time\n",
    "\n",
    "def scrape_quotes():\n",
    "    # 创建SSL上下文，忽略SSL证书验证\n",
    "    context = ssl._create_unverified_context()\n",
    "\n",
    "    all_quotes = []\n",
    "\n",
    "    # 记录起始时间\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 爬取前10个页面的内容\n",
    "    for page_num in range(1, 11):  # 循环迭代1到10的每个页面编号\n",
    "        url = f'https://quotes.toscrape.com/page/{page_num}/'  # 构建当前页面的URL\n",
    "        page = urlopen(url, context=context)\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "        quotes = soup.find_all('div', class_='quote')  # 找到当前页面中所有名言的div标签\n",
    "\n",
    "        # 遍历当前页面中的每个名言\n",
    "        for quote in quotes:\n",
    "            text = quote.find('span', class_='text').text\n",
    "            author = quote.find('small', class_='author').text\n",
    "            tags = [tag.text for tag in quote.find('div', class_='tags').find_all('a')]  # 直接生成列表\n",
    "            all_quotes.append([text, author, tags])\n",
    "\n",
    "    # 记录结束时间\n",
    "    end_time = time.time()\n",
    "\n",
    "    # 计算总耗时\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Total time taken to scrape data: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    # 将爬取到的所有名言数据存储为CSV格式文件\n",
    "    df = pd.DataFrame(all_quotes, columns=['Quote', 'Author', 'Tags'])  # 创建DataFrame对象，用于保存数据\n",
    "    df.to_csv('quotes.csv', index=False)\n",
    "\n",
    "# 使用 %prun 分析 scrape_quotes 函数的性能\n",
    "%prun scrape_quotes()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561d41b3",
   "metadata": {},
   "source": [
    "3. 模拟会员登录过程。（同上加性能分析）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67e49e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "登录成功！页面标题是： Quotes to Scrape\n",
      " Total time taken to automate login: 6.24 seconds\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "def automate_login():\n",
    "    # 启动WebDriver, 打开目标网页\n",
    "    driver = webdriver.Safari()\n",
    "    driver.get('http://quotes.toscrape.com/login')\n",
    "\n",
    "    # 查找用户名输入框并输入用户名\n",
    "    username_input = driver.find_element(By.ID, 'username')  # 通过ID定位用户名输入框\n",
    "    username_input.send_keys('username')  # 输入用户名\n",
    "\n",
    "    # 查找密码输入框并输入密码\n",
    "    password_input = driver.find_element(By.ID, 'password')  # 通过ID定位密码输入框\n",
    "    password_input.send_keys('password')  # 输入密码\n",
    "\n",
    "    # 查找登录按钮并点击\n",
    "    login_button = driver.find_element(By.CSS_SELECTOR, 'input[type=\"submit\"]')  # 通过CSS选择器定位登录按钮\n",
    "    login_button.click()  # 点击登录按钮\n",
    "\n",
    "    # 等待登录完成，最多等待10秒\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.LINK_TEXT, 'Logout'))  # 等待直到\"Logout\"链接出现\n",
    "    )\n",
    "\n",
    "    # 打印登录后的页面标题\n",
    "    print(\"登录成功！页面标题是：\", driver.title)\n",
    "\n",
    "    # 关闭浏览器\n",
    "    driver.quit()  # 退出并关闭浏览器\n",
    "\n",
    "# 记录起始时间\n",
    "start_time = time.time()\n",
    "\n",
    "# 使用 %prun 分析 automate_login 函数的性能\n",
    "%prun automate_login()\n",
    "\n",
    "# 记录结束时间\n",
    "end_time = time.time()\n",
    "\n",
    "# 计算总耗时\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Total time taken to automate login: {elapsed_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8a1c74",
   "metadata": {},
   "source": [
    "4. 爬取虚拟书店内容和图片，并存储为CSV格式，图片单独命名存储。（包含图片、价格、评价，书名等书籍所有内容。图片可用wget下载即可，无须读写。）#测试虚拟地址技术"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "792a8bb0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据爬取和保存完成。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests  # 用于下载图片，更改wget为使用requests\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "import time\n",
    "import tempfile\n",
    "\n",
    "# 创建临时目录来存储图片\n",
    "#temp_dir = tempfile.TemporaryDirectory()\n",
    "\n",
    "driver = webdriver.Safari()\n",
    "driver.get('http://books.toscrape.com')\n",
    "\n",
    "context = ssl._create_unverified_context()  \n",
    "\n",
    "books_information = []  \n",
    "\n",
    "# 爬取前10个页面的内容\n",
    "for page_num in range(1, 11):\n",
    "    url = f'http://books.toscrape.com/catalogue/page-{page_num}.html'\n",
    "    driver.get(url)\n",
    "    time.sleep(2)  # 等待页面加载\n",
    "\n",
    "    # 使用BeautifulSoup解析当前页面的HTML内容\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    books = soup.find_all('article', class_='product_pod')\n",
    "\n",
    "    for book in books:\n",
    "        book_relative_url = book.find('h3').find('a')['href']\n",
    "        book_url = 'http://books.toscrape.com/catalogue/' + book_relative_url\n",
    "        \n",
    "        # 打开书籍详情页\n",
    "        book_page = urlopen(book_url, context=context)\n",
    "        book_soup = BeautifulSoup(book_page, 'html.parser')\n",
    "        \n",
    "        # 提取书籍详情\n",
    "        title = book_soup.find('h1').text\n",
    "        price = book_soup.find('p', class_='price_color').text\n",
    "        rating = book_soup.find('p', class_='star-rating')['class'][1]\n",
    "        availability = book_soup.find('p', class_='instock availability').text.strip()\n",
    "        description = book_soup.find('meta', {'name': 'description'})['content'].strip()\n",
    "        image_url = 'http://books.toscrape.com/' + book_soup.find('img')['src'].replace('../', '')\n",
    "        \n",
    "        # 下载图片并保存 #保存到临时目录\n",
    "        #image_filename = os.path.join(temp_dir.name, f\"{title.replace('/', '_')}.jpg\")\n",
    "        #image_data = requests.get(image_url).content\n",
    "        image_filename = f\"images/{title.replace('/', '_')}.jpg\"\n",
    "        if not os.path.exists('images'):\n",
    "            os.makedirs('images')\n",
    "        image_data = requests.get(image_url).content\n",
    "        with open(image_filename, 'wb') as handler:\n",
    "            handler.write(image_data)\n",
    "        \n",
    "        # 存储书籍信息\n",
    "        book_info = {\n",
    "            'Title': title,\n",
    "            'Price': price,\n",
    "            'Rating': rating, #how many stars\n",
    "            'Availability': availability,\n",
    "            'Description': description,\n",
    "            'Image': image_filename\n",
    "        }\n",
    "        books_information.append(book_info)\n",
    "\n",
    "# 关闭WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# 将书籍数据存储为CSV文件\n",
    "#csv_filename = os.path.join(temp_dir.name, 'books.csv')\n",
    "df = pd.DataFrame(books_information)\n",
    "df.to_csv('books.csv', index=False)\n",
    "\n",
    "print(\"数据爬取和保存完成。\")\n",
    "#print(f\"书籍数据和图片保存在临时目录: {temp_dir.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88c09cf",
   "metadata": {},
   "source": [
    "5.爬取豆瓣影评（网址：https://movie.douban.com ； 爬取：年度排行榜电影的影评；要求：至少一类电影的影评、至少10部电影的影评，比如：评分最高的外国语电影）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4b74a0f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching reviews for movie: 肖申克的救赎 (ID: 1292052)\n",
      "Fetched 200 reviews for movie: 肖申克的救赎 (ID: 1292052)\n",
      "Fetching reviews for movie: 霸王别姬 (ID: 1291546)\n",
      "Fetched 200 reviews for movie: 霸王别姬 (ID: 1291546)\n",
      "Fetching reviews for movie: 阿甘正传 (ID: 1292720)\n",
      "Fetched 200 reviews for movie: 阿甘正传 (ID: 1292720)\n",
      "Fetching reviews for movie: 泰坦尼克号 (ID: 1292722)\n",
      "Fetched 200 reviews for movie: 泰坦尼克号 (ID: 1292722)\n",
      "Fetching reviews for movie: 千与千寻 (ID: 1291561)\n",
      "Fetched 200 reviews for movie: 千与千寻 (ID: 1291561)\n",
      "Fetching reviews for movie: 这个杀手不太冷 (ID: 1295644)\n",
      "Fetched 200 reviews for movie: 这个杀手不太冷 (ID: 1295644)\n",
      "Fetching reviews for movie: 美丽人生 (ID: 1292063)\n",
      "Fetched 200 reviews for movie: 美丽人生 (ID: 1292063)\n",
      "Fetching reviews for movie: 星际穿越 (ID: 1889243)\n",
      "Fetched 200 reviews for movie: 星际穿越 (ID: 1889243)\n",
      "Fetching reviews for movie: 盗梦空间 (ID: 3541415)\n",
      "Fetched 200 reviews for movie: 盗梦空间 (ID: 3541415)\n",
      "Fetching reviews for movie: 楚门的世界 (ID: 1292064)\n",
      "Fetched 200 reviews for movie: 楚门的世界 (ID: 1292064)\n",
      "All reviews fetched and saved.\n"
     ]
    }
   ],
   "source": [
    "#爬取豆瓣top250的前十部电影的前十页影评\n",
    "import requests # 导入requests模块，用于发送HTTP请求\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "import time\n",
    "import csv \n",
    "\n",
    "# 设置用户代理池，防止被反爬机制封杀\n",
    "user_agents = [\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3', \n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/12.1.1 Safari/605.1.15',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:76.0) Gecko/20100101 Firefox/76.0',\n",
    "    # 加更多的用户代理\n",
    "]\n",
    "\n",
    "# 随机选择一个用户代理\n",
    "def get_random_user_agent():\n",
    "    return random.choice(user_agents)\n",
    "\n",
    "# 爬取影评函数\n",
    "def fetch_reviews(movie_id, movie_name, pages=10):\n",
    "    headers = {'User-Agent': get_random_user_agent()}  # 设置请求头，使用随机选择的用户代理\n",
    "    reviews = []  # 初始化影评列表\n",
    "\n",
    "    for page in range(0, pages):\n",
    "        url = f'https://movie.douban.com/subject/{movie_id}/comments?start={page*20}&limit=20&status=P&sort=new_score'# 构造请求URL\n",
    "        response = requests.get(url, headers=headers) \n",
    "        \n",
    "        if response.status_code != 200:  # 如果响应状态码不是200，打印错误信息\n",
    "            print(f\"Failed to fetch page {page+1} for movie {movie_id}\")\n",
    "            continue  # 跳过当前循环，继续下一页\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        comments = soup.find_all('div', class_='comment')\n",
    "        \n",
    "        for comment in comments:\n",
    "            text = comment.find('span', class_='short').text.strip()\n",
    "            reviews.append((movie_name, text))\n",
    "        \n",
    "        # 随机暂停1到3秒，模拟真人行为，防止被封\n",
    "        time.sleep(random.uniform(1, 3))\n",
    "        \n",
    "    return reviews\n",
    "\n",
    "# 主函数，爬取豆瓣电影TOP250的影评\n",
    "def main():\n",
    "    top_250_url = 'https://movie.douban.com/top250'\n",
    "    response = requests.get(top_250_url, headers={'User-Agent': get_random_user_agent()})\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    movie_tags = soup.find_all('div', class_='hd')\n",
    "    \n",
    "    movie_info = []\n",
    "    for tag in movie_tags[:10]:     # 这里限制为前10部电影\n",
    "        movie_link = tag.a['href']  # 获取电影链接\n",
    "        movie_id = movie_link.split('/')[-2]  # 提取电影ID\n",
    "        movie_name = tag.a.span.text.strip()\n",
    "        movie_info.append((movie_id, movie_name))\n",
    "    \n",
    "    all_reviews = []\n",
    "    for movie_id, movie_name in movie_info:\n",
    "        print(f\"Fetching reviews for movie: {movie_name} (ID: {movie_id})\")  # 打印当前处理的电影信息\n",
    "        reviews = fetch_reviews(movie_id, movie_name, pages=10) \n",
    "        all_reviews.extend(reviews)\n",
    "        print(f\"Fetched {len(reviews)} reviews for movie: {movie_name} (ID: {movie_id})\")  # 打印已获取影评数量\n",
    "    \n",
    "    # 保存结果到CSV文件\n",
    "    with open('douban_reviews.csv', 'w', encoding='utf-8', newline='') as f:\n",
    "        writer = csv.writer(f)  # 创建CSV写入对象\n",
    "        writer.writerow(['电影名', '影评'])  # 写入CSV文件的表头\n",
    "        writer.writerows(all_reviews)  #写入所有影评\n",
    "    \n",
    "    print(\"All reviews fetched and saved.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dc809c",
   "metadata": {},
   "source": [
    "添加一下技术：（1）多进程多线程技术（2）数据库交互（redis, mongodb）（3）虚拟地址 （在Spyder上测试成功）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78375903",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnPoolWorker-5:\n",
      "Process SpawnPoolWorker-2:\n",
      "Process SpawnPoolWorker-4:\n",
      "Process SpawnPoolWorker-3:\n",
      "Process SpawnPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process SpawnPoolWorker-7:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process SpawnPoolWorker-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'fetch_reviews' on <module '__main__' (built-in)>\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'fetch_reviews' on <module '__main__' (built-in)>\n",
      "AttributeError: Can't get attribute 'fetch_reviews' on <module '__main__' (built-in)>\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'fetch_reviews' on <module '__main__' (built-in)>\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'fetch_reviews' on <module '__main__' (built-in)>\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'fetch_reviews' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-8:\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'fetch_reviews' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'fetch_reviews' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'fetch_reviews' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'fetch_reviews' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-15:\n",
      "Process SpawnPoolWorker-18:\n",
      "Process SpawnPoolWorker-17:\n",
      "Process SpawnPoolWorker-13:\n",
      "Process SpawnPoolWorker-14:\n",
      "Process SpawnPoolWorker-12:\n",
      "Process SpawnPoolWorker-11:\n",
      "Process SpawnPoolWorker-16:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 365, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 430, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 395, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 79\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll reviews fetched and saved to MongoDB.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 79\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[3], line 65\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# 使用多进程爬取影评\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Pool(cpu_count()) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m---> 65\u001b[0m     results \u001b[38;5;241m=\u001b[39m pool\u001b[38;5;241m.\u001b[39mmap(fetch_reviews, movie_info)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# 将所有影评展平为一个列表\u001b[39;00m\n\u001b[1;32m     68\u001b[0m all_reviews \u001b[38;5;241m=\u001b[39m [review \u001b[38;5;28;01mfor\u001b[39;00m sublist \u001b[38;5;129;01min\u001b[39;00m results \u001b[38;5;28;01mfor\u001b[39;00m review \u001b[38;5;129;01min\u001b[39;00m sublist]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_async(func, iterable, mapstar, chunksize)\u001b[38;5;241m.\u001b[39mget()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event\u001b[38;5;241m.\u001b[39mwait(timeout)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/threading.py:629\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    627\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 629\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cond\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m    328\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "import time\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# 设置用户代理池，防止被反爬机制封杀\n",
    "user_agents = [\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/12.1.1 Safari/605.1.15',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:76.0) Gecko/20100101 Firefox/76.0',\n",
    "]\n",
    "\n",
    "# 随机选择一个用户代理\n",
    "def get_random_user_agent():\n",
    "    return random.choice(user_agents)\n",
    "\n",
    "# 爬取影评函数\n",
    "def fetch_reviews(movie):\n",
    "    movie_id, movie_name = movie\n",
    "    headers = {'User-Agent': get_random_user_agent()}\n",
    "    reviews = []\n",
    "\n",
    "    for page in range(0, 2):  # 爬取前10页\n",
    "        url = f'https://movie.douban.com/subject/{movie_id}/comments?start={page*20}&limit=20&status=P&sort=new_score'\n",
    "        response = requests.get(url, headers=headers)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to fetch page {page+1} for movie {movie_id}\")\n",
    "            continue\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        comments = soup.find_all('div', class_='comment')\n",
    "        \n",
    "        for comment in comments:\n",
    "            text = comment.find('span', class_='short').text.strip()\n",
    "            reviews.append({\n",
    "                'movie_name': movie_name,\n",
    "                'review': text\n",
    "            })\n",
    "        \n",
    "        time.sleep(random.uniform(1, 3))\n",
    "        \n",
    "    return reviews\n",
    "\n",
    "# 主函数，爬取豆瓣电影TOP250的影评\n",
    "def main():\n",
    "    top_250_url = 'https://movie.douban.com/top250'\n",
    "    response = requests.get(top_250_url, headers={'User-Agent': get_random_user_agent()})\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    movie_tags = soup.find_all('div', class_='hd')\n",
    "    \n",
    "    movie_info = []\n",
    "    for tag in movie_tags[:2]:  # 限制为前10部电影\n",
    "        movie_link = tag.a['href']\n",
    "        movie_id = movie_link.split('/')[-2]\n",
    "        movie_name = tag.a.span.text.strip()\n",
    "        movie_info.append((movie_id, movie_name))\n",
    "\n",
    "    # 使用多进程爬取影评\n",
    "    with Pool(cpu_count()) as pool:\n",
    "        results = pool.map(fetch_reviews, movie_info)\n",
    "    \n",
    "    # 将所有影评展平为一个列表\n",
    "    all_reviews = [review for sublist in results for review in sublist]\n",
    "\n",
    "    # 连接MongoDB并保存数据\n",
    "    client = MongoClient('localhost', 27017)\n",
    "    db = client['douban']\n",
    "    collection = db['reviews']\n",
    "    collection.insert_many(all_reviews)\n",
    "    \n",
    "    print(\"All reviews fetched and saved to MongoDB.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f68560",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
